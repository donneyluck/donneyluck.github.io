#+title:  Game server interview questions
#+date:       [2024-08-26 Mon 17:58]
#+filetags:   :notes:
#+description: Common server interview questions and answers collections very helpful
* 游戏服务器面试题合集
** TCP 的核心意涵是什么？
TCP 是面向连接的可靠的传送协议。核心意涵就是面向连接与可靠，对于使用TCP socket而言我们要管理好socket的建立连接，断开连接等。同时对于业务逻辑而言TCP socket是可靠的不会丢包的，比如我发送ABCDE,这些数据包，不会出现丢包(ABDE)与乱序的情况(ACBED)。
** 为什么TCP需要封包拆包协议？
应用层发送数据的时候，每次发送会被开发人员认为是一个独立的数据包，可是在底层，由于TCP是可靠的传送协议，每次发送数据都要收到确认。所以底层有可能把应用层的两个数据包合并在一起发送，发送到另外一段的时候，可能一次收到两个应用层的数据包，而我们解析这些数据包的时候需要分成两个，所以我们在发送TCP命令包的时候要用标识能分开这两个数据包。所以就需要我们加一个封包拆包的协议。
*** TCP 协议传输过程
TCP 协议是面向流的协议，是流式的，没有业务上的分段，只会根据当前套接字缓冲区的情况进行拆包或者粘包:
[[file:assets/notes/tcp_pack/1.jpg]]
*** TCP 粘包、拆包图解
由于 TCP 传输协议面向流的，没有消息保护边界。一方发送的多个报文可能会被合并成一个大的报文进行传输，这就是粘包；也可能发送的一个报文，可能会被拆分成多个小报文，这就是拆包。
下图演示了粘包、拆包的过程，client 分别发送了两个数据包 D1 和 D2 给 server，server 端一次读取到字节数是不确定的，因此可能可能存在以下几种情况：
[[file:assets/notes/tcp_pack/2.png]]

关于这几种情况说明如下：
server 端分两次读取到了两个独立的数据包，分别是 D1 和 D2，没有粘包和拆包
server 一次接受到了两个数据包，D1 和 D2 粘合在一起，称之为 TCP 粘包
server 分两次读取到了数据包，第一次读取到了完整的 D1 包和 D2 包的部分内容，第二次读取到了 D2 包的剩余内容，这称之为 TCP 拆包
server 分两次读取到了数据包，第一次读取到了 D1 包的部分内容 D1_1，第二次读取到了 D1 包的剩余部分内容 D1_2 和完整的 D2 包。
由于发送方发送的数据，可能会发生粘包、拆包的情况。这样，对于接收端就难于分辨出来了，因此必须提供科学的机制来解决粘包、拆包问题，这就是协议的作用。
在介绍协议之前，我们先了解一下粘包、拆包产生的原因。
*** 粘包、拆包产生的原因
粘包、拆包问题的产生原因归纳为以下 3 种：
**** socket 缓冲区与滑动窗口
每个 TCP socket 在内核中都有一个发送缓冲区(SO_SNDBUF )和一个接收缓冲区(SO_RCVBUF)，TCP 的全双工的工作模式以及 TCP 的滑动窗口便是依赖于这两个独立的 buffer 的填充状态。
***** SO_SNDBUF:
进程发送的数据的时候假设调用了一个 send 方法，最简单情况（也是一般情况），将数据拷贝进入 socket 的内核发送缓冲区之中，然后 send 便会在上层返回。
换句话说，send 返回之时，数据不一定会发送到对端去（和 write 写文件有点类似），send 仅仅是把应用层 buffer 的数据拷贝进 socket 的内核发送 buffer 中。
***** SO_RCVBUF:
把接受到的数据缓存入内核，应用进程一直没有调用 read 进行读取的话，此数据会一直缓存在相应 socket 的接收缓冲区内。再啰嗦一点，不管进程是否读取 socket，对端
发来的数据都会经由内核接收并且缓存到 socket 的内核接收缓冲区之中。read 所做的工作，就是把内核缓冲区中的数据拷贝到应用层用户的 buffer 里面，仅此而已。
***** 滑动窗口:
TCP 连接在三次握手的时候，会将自己的窗口大小(window size)发送给对方，其实就是 SO_RCVBUF 指定的值。之后在发送数据的时，发送方必须要先确认接收方的窗口没有被填充满，如果没有填满，则可以发送。
每次发送数据后，发送方将自己维护的对方的 window size 减小，表示对方的 SO_RCVBUF 可用空间变小。
当接收方处理开始处理 SO_RCVBUF 中的数据时，会将数据从 socket 在内核中的接受缓冲区读出，此时接收方的 SO_RCVBUF 可用空间变大，即 window size 变大，接受
方会以 ack 消息的方式将自己最新的 window size 返回给发送方，此时发送方将自己的维护的接受的方的 window size 设置为 ack 消息返回的 window size。
此外，发送方可以连续的给接受方发送消息，只要保证对方的 SO_RCVBUF 空间可以缓存数据即可，即 window size>0。当接收方的 SO_RCVBUF 被填充满时，此时
window size=0，发送方不能再继续发送数据，要等待接收方 ack 消息，以获得最新可用的 window size。
***** 现在来看一下 SO_RCVBUF 和滑动窗口是如何造成粘包、拆包的？
粘包：假设发送方的每 256 bytes 表示一个完整的报文，接收方由于数据处理不及时，这 256 个字节的数据都会被缓存到 SO_RCVBUF 中。如果接收方的 SO_RCVBUF 中缓存了多个报文，那么对于接收方而言，这就是粘包。
拆包：考虑另外一种情况，假设接收方的 window size 只剩了 128，意味着发送方最多还可以发送 128 字节，而由于发送方的数据大小是 256 字节，因此只能发送前 128 字节，等到接收方 ack 后，才能发送剩余字节。这就造成了拆包。
**** MSS/MTU 限制
MTU (Maxitum Transmission Unit,最大传输单元) 是链路层对一次可以发送的最大数据的限制。
MSS (Maxitum Segment Size,最大分段大小) 是 TCP 报文中 data 部分的最大长度，是传输层对一次可以发送的最大数据的限制。
要了解 MSS/MTU，首先需要回顾一下 TCP/IP 五层网络模型模型:

[[file:assets/notes/tcp_pack/3.png]]
数据在传输过程中，每经过一层，都会加上一些额外的信息：
1. 应用层：只关心发送的数据 DATA，将数据写入 socket 在内核中的缓冲区 SO_SNDBUF 即返回，操作系统会将 SO_SNDBUF 中的数据取出来进行发送。
2. 传输层：会在 DATA 前面加上 TCP Header(20 字节)
3. 网络层：会在 TCP 报文的基础上再添加一个 IP Header，也就是将自己的网络地址加入到报文中。IPv4 中 IP Header 长度是 20 字节，IPV6 中 IP Header 长度是 40 字节。
4. 链路层：加上 Datalink Header 和 CRC。会将 SMAC(Source Machine，数据发送方的 MAC 地址)，DMAC(Destination Machine，数据接受方的 MAC 地址 )和 Type 域加入。SMAC+DMAC+Type+CRC 总长度为 18 字节。
5. 物理层：进行传输

在回顾这个基本内容之后，再来看 MTU 和 MSS。MTU 是以太网传输数据方面的限制，每个以太网帧最大不能超过 1518bytes。
刨去以太网帧的帧头(DMAC+SMAC+Type 域）14Bytes 和帧尾(CRC 校验)4Bytes，那么剩下承载上层协议的地方也就是 Data 域最大就只能有 1500Bytes 这个值 我们就把它称之为 MTU。

MSS 是在 MTU 的基础上减去网络层的 IP Header 和传输层的 TCP Header 的部分，这就是 TCP 协议一次可以发送的实际应用数据的最大大小。

MSS = MTU(1500) -IP Header(20 or 40)-TCP Header(20)

由于 IPV4 和 IPV6 的长度不同，在 IPV4 中，以太网 MSS 可以达到 1460byte；在 IPV6 中，以太网 MSS 可以达到 1440byte。
发送方发送数据时，当 SO_SNDBUF 中的数据量大于 MSS 时，操作系统会将数据进行拆分，使得每一部分都小于 MSS，也形成了拆包，然后每一部分都加上 TCP Header，构成多个完整的 TCP 报文进行发送，当然经过网络层和数据链路层的时候，还会分别加上相应的内容。
另外需要注意的是：对于本地回环地址(lookback)不需要走以太网，所以不受到以太网 MTU=1500 的限制。linux 服务器上输入 ifconfig 命令，可以查看不同网卡的 MTU 大小，如下：

[[file:assets/notes/tcp_pack/4.jpg]]
上图显示了 2 个网卡信息：
eth0 需要走以太网，所以 MTU 是 1500；
lo 是本地回环，不需要走以太网，所以不受 1500 的限制。
**** Nagle 算法
TCP/IP 协议中，无论发送多少数据，总是要在数据(DATA)前面加上协议头(TCP Header+IP Header)，同时，对方接收到数据，也需要发送 ACK 表示确认。
即使从键盘输入的一个字符，占用一个字节，可能在传输上造成 41 字节的包，其中包括 1 字节的有用信息和 40 字节的首部数据。这种情况转变成了 4000%的消耗，这样的情况对于重负载的网络来是无法接受的。称之为"糊涂窗口综合征"。
为了尽可能的利用网络带宽，TCP 总是希望尽可能的发送足够大的数据。（一个连接会设置 MSS 参数，因此，TCP/IP 希望每次都能够以 MSS 尺寸的数据块来发送数据）。Nagle 算法就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。
Nagle 算法的基本定义是任意时刻，最多只能有一个未被确认的小段。 所谓“小段”，指的是小于 MSS 尺寸的数据块，所谓“未被确认”，是指一个数据块发送出去后，没有收到对方发送的 ACK 确认该数据已收到。
Nagle 算法的规则：
1. 如果 SO_SNDBUF 中的数据长度达到 MSS，则允许发送；
2. 如果该 SO_SNDBUF 中含有 FIN，表示请求关闭连接，则先将 SO_SNDBUF 中的剩余数据发送，再关闭；
3. 设置了 TCP_NODELAY=true 选项，则允许发送。TCP_NODELAY 是取消 TCP 的确认延迟机制，相当于禁用了 Negale 算法。正常情况下，当 Server 端收到数据之后，它并不会马上向 client 端发送 ACK，
   而是会将 ACK 的发送延迟一段时间（假一般是 40ms），它希望在 t 时间内 server 端会向 client 端发送应答数据，这样 ACK 就能够和应答数据一起发送，就像是应答数据捎带着 ACK 过去。
   当然，TCP 确认延迟 40ms 并不是一直不变的，TCP 连接的延迟确认时间一般初始化为最小值 40ms，随后根据连接的重传超时时间（RTO）、上次收到数据包与本次接收数据包的时间间隔等参数进行不断调整。
   另外可以通过设置 TCP_QUICKACK 选项来取消确认延迟。
4. 未设置 TCP_CORK 选项时，若所有发出去的小数据包（包长度小于 MSS）均被确认，则允许发送;
5. 上述条件都未满足，但发生了超时（一般为 200ms），则立即发送。
*** 通信协议
在了解了粘包、拆包产生的原因之后，现在来分析接收方如何对此进行区分。道理很简单，如果存在不完整的数据(拆包)，则需要继续等待数据，直至可以构成一条完整的请求或者响应。
通过定义通信协议(protocol)，可以解决粘包、拆包问题。协议的作用就定义传输数据的格式。这样在接受到的数据的时候:
如果粘包了，就可以根据这个格式来区分不同的包
如果拆包了，就等待数据可以构成一个完整的消息来处理。
**** 定长协议
定长协议：顾名思义，就是指定一个报文的必须具有固定的长度。例如，我们规定每 3 个字节，表示一个有效报文，如果我们分 4 次总共发送以下 9 个字节：
|---+----+------+----|
| A | BC | DEFG | HI |
|---+----+------+----|
那么根据协议，我们可以判断出来，这里包含了 3 个有效的请求报文，如下：
|-----+-----+-----|
| ABC | DEF | GHI |
|-----+-----+-----|
在定长协议中：
发送方，必须保证发送报文长度是固定的。如果报文字节长度不能满足条件，如规定长度是 1024 字节，但是实际需要发送的内容只有 900 个字节，那么不足的部分可以补充 0。因此定长协议可能会浪费带宽。
接收方，每读取到固定长度的内容时，则认为读取到了一个完整的报文。
**** 特殊字符分割协议
在包尾部增加回车或者空格符等特殊字符进行分割 。例如，按行解析，遇到字符\n、\r\n 的时候，就认为是一个完整的数据包。对于以下二进制字节流：
|--------------|
| ABC\nDEF\r\n |
|--------------|
那么根据协议，我们可以判断出来，这里包含了 2 个有效的请求报文
|-----+-----|
| ABC | DEF |
|-----+-----|
在特殊字符分隔符协议中：
发送方，需要在发送一个报文时，需要在报文尾部添加特殊分割符号；
接收方，在接收到报文时，需要对特殊分隔符进行检测，直到检测到一个完整的报文时，才能进行处理。

在使用特殊字符分隔符协议的时候，需要注意的是，我们选择的特殊字符，一定不能在消息体中出现，否则可能会出现错误的拆包。
例如，发送方希望把”12\r\n34”，当成一个完整的报文，如果是按行拆分，那么就会错误的拆分为 2 个报文。一种解决策略是，发
送方对需要发送的内容预先进行 base64 编码，由于 base64 编码只包含 64 个字符：0-9、a-z、A-Z、+、/，我们可以选择这 64 个字
符之外的特殊字符作为分隔符。
**** 变长协议
在解析时，先读取内容长度 Length，其值为实际消息体内容(Content)占用的字节数，之后必须读取到这么多字节的内容，才认为是一个完整的数据报文。
|--------+---------|
| header | body    |
|--------+---------|
| Length | Content |
|--------+---------|
在变长协议中：
发送方，发送数据之前，需要先获取需要发送内容的二进制字节大小，然后在需要发送的内容前面添加一个整数，表示消息体二进制字节的长度。
接收方，在解析时，先读取内容长度 Length，其值为实际消息体内容(Content)占用的字节数，之后必须读取到这么多字节的内容，才认为是一个完整的数据报文。
**** 序列化
序列化本质上已经不是为了解决粘包和拆包问题，而是为了在网络开发中可以更加的便捷。
在变长协议中，我们看到可以在实际要发送的数据之前加上一个 length 字段，表示实际要发送的数据的长度。
这实际上给我们了一个很好的思路，我们完全可以将一个对象转换成二进制字节，来进行通信，例如使用一个 Request 对象表示请求，使用一个 Response 对象表示响应。
|----------+---------------------------------+-------------------------------------------------------|
| frame    | support language                | web                                                   |
|----------+---------------------------------+-------------------------------------------------------|
| jdk      | Java                            |                                                       |
|----------+---------------------------------+-------------------------------------------------------|
| hessian  | Support multiple not include go | http://hessian.caucho.com/                            |
|----------+---------------------------------+-------------------------------------------------------|
| fst      | Java                            | https://github.com/RuedigerMoeller/fast-serialization |
|----------+---------------------------------+-------------------------------------------------------|
| protobuf | Almost all languages            | https://developers.google.cn/protocol-buffers/        |
|----------+---------------------------------+-------------------------------------------------------|
| msgpack  | Almost all languages            | https://msgpack.org/                                  |
|----------+---------------------------------+-------------------------------------------------------|
提示：xml、json 也属于序列化框架的范畴，上面的表格中并没有列出。

一些网络通信的 RPC 框架通常会支持多种序列化方式，例如 dubbo 支持 hessian、json、kyro、fst 等。
在支持多种序列化框架的情况下，在协议中通常需要有一个字段来表示序列化的类型，例如，我们可以将上述变长协议的格式改造为：
|--------+------------+---------|
| Length | serializer | Content |
|--------+------------+---------|
这里使用 1 个字节表示 Serializer 的值，使用不同的值代表不同的框架。

发送方，选择好序列化框架后编码后，需要指定 Serializer 字段的值。
接收方，在解码时，根据 Serializer 的值选择对应的框架进行反序列化
**** 压缩
通常，为了节省网络开销，在网络通信时，可以考虑对数据进行压缩。常见的压缩算法有 lz4、snappy、gzip 等。在选择压缩算法时，我们主要考虑压缩比以及解压缩的效率。
我们可以在网络通信协议中，添加一个 compress 字段，表示采用的压缩算法：
|--------+------------+----------+---------|
| Length | serializer | compress | Content |
|--------+------------+----------+---------|
通常，我们没有必要使用一个字节，来表示采用的压缩算法，1个字节可以标识 256 种可能情况，而常用压缩算法也就那么几种，因此通常只需要使用 2~3 个 bit 来表示采用的压缩算法即可。

另外，由于数据量比较小的时候，压缩比并不会太高，没有必要对所有发送的数据都进行压缩，只有再超过一定大小的情况下，才考虑进行压缩。
如 rocketmq，producer 在发送消息时，默认消息大小超过 4k，才会进行压缩。因此，compress 字段，应该有一个值，表示没有使用任何压缩算法，例如使用 0。
**** 查错校验码
一些通信协议传输的数据中，还包含了查错校验码。典型的算法如 CRC32、Adler32 等。java 对这两种校验方式都提供了支持，java.util.zip.Adler32、java.util.zip.CRC32
|--------+------------+----------+---------+-------|
| Length | serializer | compress | Content | CRC32 |
|--------+------------+----------+---------+-------|
这里并不对 CRC32、Adler32 进行详细说明，主要是考虑，为什么需要进行校验？
有人说是因为考虑到安全，这个理由似乎并不充分，因为我们已经有了 TLS 层的加密，CRC32、Adler32 的作用不应该是为了考虑安全。
一位同事的观点，我非常赞同：二进制数据在传输的过程中，可能因为电磁干扰，导致一个高电平变成低电平，或者低电平变成高电平。这种情况下，数据相当于受到了污染，此时通过 CRC32 等校验值，则可以验证数据的正确性。
另外，通常校验机制在通信协议中，是可选的配置的，并不需要强制开启，其虽然可以保证数据的正确，但是计算校验值也会带来一些额外的性能损失。如 Mysql 主从同步，虽然高版本默认开启 CRC32 校验，但是也可以通过配置禁用。
**** 小结
本节通过一些基本的案例，讲解了在 TCP 编程中，如何通过协议来解决粘包、拆包问题。在实际开发中，通常我们的协议会更加复杂。
例如，一些 RPC 框架，会在协议中添加唯一标识一个请求的 ID，一些支持双向通信的 RPC 框架，如 sofa-bolt，还会添加一个方向信息等。
当然，所谓复杂，无非是在协议中添加了某个字段用于某个用途，只要弄清楚这些字段的含义，也就不复杂了。
** TCP 如何设计 封包与拆包协议？
设计TCP封包拆包协议主要有两种方式，一种是大小+内容模式+校验模式，一种是特殊的分割符号的模式，比如\r\n, http协议就采用的是\r\n来进行分割, 还有一种固定长度模式。
** UDP的优点与缺点分别是什么？
UDP传送数据速度快，性能好，缺点是UDP发送完数据就不管了，数据传送中有可能丢包，同时数据包走的网络路径可能不一样，会导致先发的数据包后到,后发的数据包先到，这样就没有正确的时序性。
** Redis 在游戏服务器开发中有什么作用？
Redis 在游戏开发中主要作用有:作为mem cache 数据库，将数据缓存到内存里面。Redis的订阅与发布系统可以作为多游戏服务器之间通讯的工具。Redis的有序集合等可以作为游戏的排行榜(zscore)。
** 游戏服务器开发采用什么样的编程语言好？
目前市面上找平游戏服务器的主流的变成语言分别如下。
第一档: C++ 与Java。占据了企业招聘里面的绝大部分;
第二档: Go, Python, C#, PHP, Node.js, Lua。
** 什么是弱联网游戏？
弱联网游戏指的是玩家游戏的时候只是自己一个人完，不涉及多人同时交互，这种我们叫做弱联网游戏，同时也提供一些联网的功能，比如购买道具，社交，公告，邮件，排行等等。
** 游戏服务器开发主流的高并发方式有哪些？
游戏服务器开发对性能要求非常的高，同时要支持高并发，充分发挥硬件性能，提升高并发发挥硬件性能，游戏服务器有两种模式的架构，一种是多进程单线程架构，一种是多进程多线程架构
** 游戏服务器用Linux操作系统还是Windows操作系统？
目前主流的游戏服务器都基于Linux操作系统的，因为Linux操作系统一直做服务器，并且很多主流的代码模块框架都是优先基于Linux的，比如Redis等，所以一般游戏服务器都用Linux作为服务器的操作系统。
** 游戏服务器开发如何调试？
游戏服务器开发对开发人员的要求非常的高, 特别是线上环境，处理的数据量比较大，所以断点调试这种方法，不大适合服务器。
服务器一般采用的调试就是打印查看日志
通过日志来分析对应的问题
所以一个好的日志系统对于服务器来说是非常重要的，当然没有断点调试就对开发人员要求更好，对程序把控的能力更强。
** 游戏服务器中主流的同步方式有哪些？
游戏服务器开发中主流的同步方式有状态同步和帧同步
*** 帧同步
帧同步是每帧同步玩家的操作，把所有的业务逻辑放到客户端计算，大家同样的操作，同样的代码得到同样的结果，帧同步的有点是性能好，缺点是容易作弊。
*** 状态同步
状态同步，就是服务器上跑游戏，各个客户端把操作输入发送给服务器，服务器决定处理的结果，把结果广播给客户端，然后客户端播放动画。状态同步的优点是不容易作弊，缺点是实时性不如帧同步。
** 游戏服务器如何能承载大量的玩家在线？
当我们分析一个服务器能承载多大量的时候，一般我们要配置好单服(一个服务器组,可能是一台机器，也可能是几台)最多可带多少人，什么样的配置带多少人，这个需要我们把代码写好。提前设定好对应的承载量，单服设置好以后，我们再来通过扩展物理机器，来吃掉流量。
** MMO RPG里面的AOI是什么意思？
MMORPG游戏可能有好几千人在同时玩游戏，如果一个人的状态改变了，要通知所有其他的好几千人，这个其实服务器是很难承受的，那么当我们一个玩家的状态有变化的时候，只要通知他周围对这个玩家感兴趣的人，这个叫做AOI，这样可以减少数据的传递，提升服务器的性能。
** 网络游戏如何做世界排行榜？
排行榜是服务器经常需要用的一个功能，这个是为了增强top玩家的荣誉感,世界排行榜是非常重要的功能，Redis 对全服的玩家进行排序，使用的是有序队列,当我们更新玩家战绩的时候Redis就会帮我们更新排序好，请求排行榜的时候，只要获取就可以了。
** 网路游戏如何对接第三方的支付？
目前第三方的支付都非常的成熟，比如微信支付，支付宝支付，那么游戏服务器如何与这些来对接呢？一般的思路是游戏服务器搭建一个http server, 提供一个地址，给第三方的支付服务器回调，当我们的客户端调用第三方SDK来支付一个商品的时候，第三方支付就会调用我们的回调地址通知我们，用户购买了某个商品，收到通知以后，我们在服务器上给玩家发货，把玩家的货物信息更新到数据库。
** 服务器开发中同步IO与异步IO的区别是什么？
IO操作指的是当我们从外部设备(磁盘，网卡)读写数据的时候，CPU要等待外部设备处理完，如果是同步IO，那么这个线程就同步的等在这个IO请求上，直到处理完成，这样这个线程就会被挂起，而不可以做别的，异步IO是发完IO请求以后，我们不等结果立马返回做其他的事情，等IO结果完成了以后再来处理。同步IO会导致线程挂起，异步IO可以使线程做其他的一些事情，具体使用同步IO，还是异步IO要从服务器的整体架构上去考虑。
** 各大编程语言的高性能的网络库主要有哪些？
Java服务器高性能的网络库有 netty, Mina等。
C/C++ 服务器高性能的网络库，可以直接使用EPOLL或IOCP，也可以使用第三方的库如libevent, libuv等。
C# 服务器开发高性能网络库可以使用SuperSocket等。
每个服务器开发语言对会有对应的高性能的网络库。
** 游戏服务器序列化/反序列化用什么样的技术？
目前服务器序列化与反序列化主要分成两种模式二进制模式与文本模式，文本模式的序列化与反序列化主要有json与xml, 二进制模式的序列化与反序列化主要有自定义的协议和google的protobuf协议。
** BASE64编码解码在服务器开发中有何作用？
BAS64编码解码，使用可打印字符(文本)来表示二进制数。在游戏开发中，如果是用文本协议，比如http, 我们要传递一个二进制数据，可以将二进制数据编码从BASE64的文本编码，然后在传递，传递完成后，再解码出来得到二进制数据，这样文本模式下传递二进制使用BASE64就成为了一个处理的方式。
** 游戏服务器如何避免内存碎片？
不管是C++服务器还是如Java这样带来垃圾回收的编程语言开发的服务器。避免内存碎片和减少GC的开销都是必不可少的。这两个其实解决问题的手段都是一样的，手段就是使用缓存池的模式，比如我这组服务器，准备负载N个玩家，那么可以为这个N问题的规模分配好对应的内存池，把那些经常要分配和释放的对象用内存池管理起来。很多人可能会问，内存池管理不就一直站内存么？其实这个问题很好理解，因为服务器和客户端App不一样，服务器所有的资源，都是为游戏服务器服务的，所以我们可以吧最大设计的负载所需要的内存一次性的开出来这样能大大节约GC开销或内存碎片。
** 如何查看游戏服务器程序是否已经发挥了机器的最大性能？
当我们很衡量一个服务器程序能带多少负载，我们可以规定一个机器的CPU, IO, 网卡等，然后看这个服务器能同时支持多少玩家不卡，等到了卡的临界点的时候，这个时候应该就是我们这个服务器程序的最大的灵界点了，如何分析这个程序是否发挥了机器的最大性能呢？这个时候我们要看各个硬件的参数，比如CPU占用率, IO, 网卡等数据，如果CPU， IO，网卡都没有达80%以上，而玩家无法再增加了，说明了我们写的代码没有完全发挥机器的性能，要去思考我们的架构和部署。
** 服务器如何做热更新？
服务器做热更新是在不关闭服务器的情况下直接热更新代码来修正代码逻辑。而游戏里面分为两类，一类为代码逻辑，一类为数据实体。当我们有成千上万的玩家同时在线的时候就有很多的数据实体，如果我们修改了数据实体的内容，肯定是无法热更新上去的，因为这些实体都存在，你添加了新的数据除非重新启动或生成数据实体否则无法热更，我们一般服务器的热更新指的不是热更新数据实体，而是更新代码逻辑，比如有个代码有bug要修正，修正以后数据实体不用改，只要更新好逻辑，这样不用重启机器,后续再掉这个逻辑的时候就已经被修正过来了。
** 服务器数据库的字符编码一般采用什么？
一般我们开发游戏服务器的时候，字符编码一般都采用Utf8, 因为Linux上UTF8的标准支持的非常好。
** 服务器守护进程有什么作用？
一般我们上线部署服务器的时候，时候有可能由于代码的错误等到只进程异常退出，当出现这样的情况是，我们要用守护进程把游戏进程重启，保证能从新开始游戏。这个就是守护进程的作用。
** Linux 如何查看服务器的内存占用等信息？
Linux有命令可以查看内存占用相关的信息，不同的Linux发型版本，可能会有一些小的差异，我们可以通过命令cat /proc/meminfo, 查看内存的整体使用情况，也可以通过top等命令来查看各个进程的一些详细信息
** 如何做服务器管理后台？
一般我们在服务器上架设一个HttpServer，HttpServer来做服务器的管理后台，通过HttpServer来操作游戏的数据库。来做为管理的后台。也可以通过访问服务器的数据库来显示当前游戏中的一些情况，方便我们对整个游戏服务器的情况做一个综合的了解。
** new和malloc的区别
| 特征               | new/delete                         | malloc/free                    |
| 分配内存的位置       | 自由存储区                           | 堆                              |
| 内存分配成功的返回值 | 完整类型指针                         | void*                          |
| 内存分配失败的返回值 | 默认抛出异常                         | 返回NULL                        |
| 分配内存的大小       | 由编译器根据类型计算得出               | 必须显式指定字节数                |
| 处理数组            | 有处理数组的new版本new[]              | 需要用户计算数组的大小后进行内存分配 |
| 已分配内存的扩充     | 无法直观地处理                        | 使用realloc简单完成              |
| 是否相互调用        | 可以，看具体的operator new/delete实现 | 不可调用new                      |
| 分配内存时内存不足   | 客户能够指定处理函数或重新制定分配器     | 无法通过用户代码进行处理           |
| 函数重载            | 允许                                | 不允许                          |
| 构造函数与析构函数   | 调用                                | 不调用                          |
** [[https://zhuanlan.zhihu.com/p/51898119][如何避免内存泄露]]
*** 使用智能指针  std::string 替代 char*
*** HOLD [[https://blog.csdn.net/okiwilldoit/article/details/110138697][Arena内存池简介]]
** HOLD 十大经典排序算法
*** 冒泡排序
比较相邻的元素。如果第一个比第二个大，就交换他们两个。
对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。
针对所有的元素重复以上的步骤，除了最后一个。
持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。
#+begin_src c++
#include <stdio.h>
void bubble_sort(int arr[], int len) {
        int i, j, temp;
        for (i = 0; i < len - 1; i++)
                for (j = 0; j < len - 1 - i; j++)
                        if (arr[j] > arr[j + 1]) {
                                temp = arr[j];
                                arr[j] = arr[j + 1];
                                arr[j + 1] = temp;
                        }
}
int main() {
        int arr[] = { 22, 34, 3, 32, 82, 55, 89, 50, 37, 5, 64, 35, 9, 70 };
        int len = (int) sizeof(arr) / sizeof(*arr);
        bubble_sort(arr, len);
        int i;
        for (i = 0; i < len; i++)
                printf("%d ", arr[i]);
        return 0;
}
#+end_src
*** 快速排序
从数列中挑出一个元素，称为 "基准"（pivot）;
重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；
递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序；
#+begin_src c++
//递归法
template <typename T>
void quick_sort_recursive(T arr[], int start, int end) {
    if (start >= end)
        return;
    T mid = arr[end];
    int left = start, right = end - 1;
    while (left < right) { //在整个范围内搜寻比枢纽元值小或大的元素，然后将左侧元素与右侧元素交换
        while (arr[left] < mid && left < right) //试图在左侧找到一个比枢纽元更大的元素
            left++;
        while (arr[right] >= mid && left < right) //试图在右侧找到一个比枢纽元更小的元素
            right--;
        std::swap(arr[left], arr[right]); //交换元素
    }
    if (arr[left] >= arr[end])
        std::swap(arr[left], arr[end]);
    else
        left++;
    quick_sort_recursive(arr, start, left - 1);
    quick_sort_recursive(arr, left + 1, end);
}
template <typename T> //整數或浮點數皆可使用,若要使用物件(class)時必須設定"小於"(<)、"大於"(>)、"不小於"(>=)的運算子功能
void quick_sort(T arr[], int len) {
    quick_sort_recursive(arr, 0, len - 1);
}
#+end_src
*** 归并排序
** [[https://blog.csdn.net/weixin_43222324/article/details/112858929][小白都能看懂的TCP三次握手四次挥手]]
** [[https://www.cioage.com/article/623158.html][大量的 TCP 连接是 TIME_WAIT 状态，有什么影响？怎么处理？]]
*** 大量的 TIME_WAIT 状态 TCP 连接存在，其本质原因是什么?
大量的短连接存在
特别是 HTTP 请求中，如果 connection 头部取值被设置为 close 时，基本都由「服务端」发起主动关闭连接
而，TCP 四次挥手关闭连接机制中，为了保证 ACK 重发和丢弃延迟数据，设置 time_wait 为 2 倍的 MSL(报文最大存活时间)
~TIME_WAIT~ 状态：
TCP 连接中，主动关闭连接的一方出现的状态;(收到 FIN 命令，进入 TIME_WAIT 状态，并返回 ACK 命令)
保持 2 个 MSL 时间，即，4 分钟;(MSL 为 2 分钟)
*** 解决上述 time_wait 状态大量存在，导致新连接创建失败的问题，一般解决办法：
(1) 客户端，HTTP 请求的头部，connection 设置为 keep-alive，保持存活一段时间：现在的浏览器，一般都这么进行了
(2) 服务器端

允许 time_wait 状态的 socket 被重用
缩减 time_wait 时间，设置为 1 MSL(即，2 mins)
结论：几个核心要点

(1) time_wait 状态的影响：

TCP 连接中，「主动发起关闭连接」的一端，会进入 time_wait 状态
time_wait 状态，默认会持续 2 MSL(报文的最大生存时间)，一般是 2x2 mins
time_wait 状态下，TCP 连接占用的端口，无法被再次使用
TCP 端口数量，上限是 6.5w(65535，16 bit)
大量 time_wait 状态存在，会导致新建 TCP 连接会出错，address already in use : connect 异常
(2) 现实场景：

服务器端，一般设置：不允许「主动关闭连接」
但 HTTP 请求中，http 头部 connection 参数，可能设置为 close，则，服务端处理完请求会主动关闭 TCP 连接
现在浏览器中， HTTP 请求 connection 参数，一般都设置为 keep-alive
Nginx 反向代理场景中，可能出现大量短链接，服务器端，可能存在
(3) 解决办法：
#+begin_src conf
vi /etc/sysctl.conf
net.ipv4.tcp_keepalive_time = 1200
#表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。
net.ipv4.ip_local_port_range = 1024 65000
#表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。
net.ipv4.tcp_max_syn_backlog = 8192
#表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。
net.ipv4.tcp_max_tw_buckets = 5000
#表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。
默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于 Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。
#+end_src
服务器端允许 time_wait 状态的 socket 被重用
缩减 time_wait 时间，设置为 1 MSL(即，2 mins)
** CLOSE_WAIT 什么情况出现？怎么处理？
四次挥手中可以得知
client 发送 fin  server 回应 ack   就会进入 close wait
如果server一直不发送 fin 就会保持在close wait状态
有可能是由于服务器bug导致的 需要查
** linux常用命令
+ linux 文本去重命令  uniq  一般配合 sort cut 一起使用
+ linux 查看cpu占用率命令   top
+ linux 查看硬盘情况 df -h
+ linux 查看进程命令  ps -x
+ linux 查看内存 free  or cat /proc/meminfo
+ linux 查看端口 netstat -tnlp     or    lsof
** HOLD [[https://zhuanlan.zhihu.com/p/260450151][一文懂网络io模型]]
单线程异步   redis
多线程异步   memcache
多进程异步   nginx
** HOLD IO多路复用
*** select
*** poll
*** epoll
+ epoll_create
+ epoll_ctrl
+ epoll_wait
** HOLD [[https://zhuanlan.zhihu.com/p/30007037][字节对齐]]
** 链表如何判环
*** 快慢指针 龟兔算法
#+begin_src c++
#include <iostream>

struct ListNode {
    int val;
    ListNode *next;
    ListNode(int x) : val(x), next(nullptr) {}
};

bool hasCycle(ListNode *head) {
    if (!head || !head->next) {
        return false;
    }

    ListNode *slow = head;
    ListNode *fast = head->next;

    while (slow != fast) {
        if (!fast || !fast->next) {
            return false;
        }
        slow = slow->next;
        fast = fast->next->next;
    }

    return true;
}

int main() {
    // 构建一个有环的链表示例
    ListNode *head = new ListNode(1);
    head->next = new ListNode(2);
    head->next->next = new ListNode(3);
    head->next->next->next = new ListNode(4);
    head->next->next->next->next = head; // 尾节点指向头节点，形成环

    std::cout << "The linked list has cycle? " << (hasCycle(head) ? "Yes" : "No") << std::endl;

    return 0;
}

#+end_src
** 大小端
大端Big Endian模式：即把数据的高字节放到低地址中
小端Little Endian模式：高字节放到高地址中
网络序 网络传输一般采用大端序
怎么测试我的电脑是小端模式还是大端模式呢
+ 将int 48存起来，然后取得其地址，再将这个地址转为char* 这时候，如果是小端存储，那么char*指针就指向48；48对应的ASCII码为字符‘0’；
#+begin_src c++
int i = 48;
int *p = &i;
char c = 0;
c = *((char*)p)
if(c == '0')
    printf("little");
else
    printf("big");
#+end_src
+ 定义变量int i=1;将 i 的地址拿到，强转成char*型，这时候就取到了 i 的低地址，这时候如果是1就是小端存储，如果是0就是大端存储
#+begin_src c++
int i = 1;
char c = *(char*(&i))
if(c)
    printf("little");
else
    printf("big");
#+end_src
+ 定义联合体，一个成员是多字节，一个是单字节，给多字节的成员赋一个最低一个字节不为0，其他字节为0 的值，再用第二个成员来判断，如果第二个字节不为0，就是小端，若为0，就是大端。
#+begin_src c++
union {
    int i;
    char c;
}un;
un.i = 1;

if(un.c == 1)
    printf("little");
else
    printf("big");
#+end_src
htons —— 把unsigned short类型从主机序转成网络字节序
ntohs —— 把unsigned short类型从网络字节序转成主机序
htonl —— 把unsigned long类型从主机序转成网络字节序
ntohl —— 把unsigned long类型从网络字节序转成主机序
** 定时器的实现
*** 用途
心跳检测 缓存数据定时刷盘 技能冷却 被动冷却 定时活动
*** 目标
统一协调处理
*** 接口设计
+ 初始化定时器 init_timer()
+ 添加定时任务 add_timer(expire_time, callback)
+ 删除定时任务 del_timer(int id) del_timer(tnode*)
+ 检测处理定时任务 handle_timer
*** 实现方式
单线程下 红黑树 最小堆 （最小堆优于红黑树） 跳跃表
多线程环境下 考虑锁的粒度 时间轮
+ 时间轮
空推进 增加层级
数组大小必须要足够大
** [[https://zhuanlan.zhihu.com/p/439331952][服务发现]]
** HOLD 树
*** 树的遍历 深度 广度 前序 中序
*** 二叉搜索树
*** 说一下最小生成树
*** 行为树
** HOLD 数据库常见问题
*** mysql
**** mysql 读写分离
**** mysql 索引用途
**** mysql B+树
**** mysql 事务
**** mysql 视图
**** mysql 锁
**** mysql 扩表方案
三种，预留字段，写成kv的形式再进行，行转列。例如 uid，key，value的表。然后进行行转列即可。还有看服务器开发大佬们常用的方法，写个新表，写三个触发器，然后闲暇时间将原表的内容插入新表，然后改名字就好了
**** 优化注册流程
**** 慢查询优化
**** mysql 为何选择b+树
*** redis
**** redis有多少种类型
Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)
**** [[最全面的Redis缓存雪崩、击穿、穿透问题解决方案][redis 缓存雪崩 击穿 穿透]]
**** redis设计与实现
**** Redis 落地的两种方式
***** RDB（Redis DataBase）：
RDB 是 Redis 的快照（Snapshot）持久化方式，它通过周期性地将内存中的数据集快照保存到磁盘上的一个二进制文件（.rdb 文件）中。
RDB 持久化可以通过配置文件中的 save 指令来设置保存的触发条件和频率。
RDB 文件通常用于备份和全量恢复，因为它是一个紧凑且经过压缩的二进制文件，可以在需要时快速地恢复到某个时间点的数据状态。
***** AOF（Append-Only File）：
AOF 是 Redis 的日志（Log）持久化方式，它以追加的方式记录每个写操作，将写操作以命令的形式追加到一个日志文件（appendonly.aof）中。
AOF 持久化可以通过配置文件中的 appendonly 指令来启用，并且可以选择不同的同步策略（如 always、everysec、no）来控制日志的刷写频率。
AOF 文件通常用于灾难恢复和增量恢复，因为它包含了所有的写操作记录，可以确保数据的完整性。
*** mongo
** TODO cplusplus
*** 友元是什么
*** 智能指针如何实现
**** shareptr
**** uniqueptr
**** weakptr
*** 虚函数
**** 虚函数怎么实现
C++中的虚函数通过虚函数表（vtable）和虚函数指针（vptr）来实现。
***** 虚函数表（vtable）：
每个包含虚函数的类都会生成一个虚函数表，用于存储该类的虚函数地址。
虚函数表是一个数组，其中存储了指向每个虚函数的函数指针。
每个类的对象都会包含一个指向其对应虚函数表的指针。
***** 虚函数指针（vptr）：
每个包含虚函数的类的对象都会包含一个虚函数指针（vptr），用于指向其对应的虚函数表。
当调用一个虚函数时，实际上是通过对象的虚函数指针找到对应的虚函数表，然后通过虚函数表中的函数指针调用实际的虚函数。
**** 虚函数表在哪
虚函数表位于静态存储区，在程序编译时就已经确定，因此对于每个类来说，其虚函数表是唯一的。
**** 虚函数怎么做替换的
虚函数的替换是通过派生类中重新定义（override）基类中的虚函数来实现的。当派生类中重新定义了基类的虚函数时，派生类中的虚函数会覆盖（替换）基类中的同名虚函数，从而改变了虚函数的行为。
**** 纯虚函数的作用
接口定义：纯虚函数定义了一个接口，强制所有派生类实现该函数。
实现多态：纯虚函数是实现多态的重要手段之一。
抽象基类：包含纯虚函数的类通常被称为抽象基类（Abstract Base Class，ABC）。
**** 为什么析构函数用虚函数
析构函数通常使用虚函数的主要原因是为了正确地释放派生类对象的资源。
当基类指针指向一个派生类对象，并且通过基类指针调用析构函数时，如果析构函数不是虚函数，那么只会调用基类的析构函数，而不会调用派生类的析构函数。这样可能导致派生类对象的资源无法正确释放，造成内存泄漏或其他问题。
**** 构造函数用虚函数会怎么样
将构造函数声明为虚函数是不推荐的，因为在对象构造期间，虚函数的多态性机制尚未建立。
*** 多态
**** 编译时多态性（静态多态性）：
编译时多态性是通过函数重载（Overloading）和模板（Template）来实现的。在编译时，根据函数参数的类型、个数和顺序来确定调用哪个函数。
函数重载允许在同一作用域内定义多个同名函数，它们的参数列表必须不同，编译器根据调用时的参数类型来决定调用哪个函数。
模板允许编写通用的函数或类，使其可以接受不同类型的参数。
**** 运行时多态性（动态多态性）：
运行时多态性是通过虚函数（Virtual Function）和继承（Inheritance）来实现的。在运行时，根据对象的实际类型来确定调用哪个函数。
虚函数是在基类中声明为虚函数的函数，派生类可以重新定义（Override）这些虚函数，通过基类指针或引用调用虚函数时，会根据对象的实际类型调用相应的派生类函数。
*** 多线程
C++提供了多种机制来支持多线程编程，其中最常用的是标准库中的<thread>头文件提供的线程类。以下是C++多线程编程的基本概念和常用技术：
**** 创建线程：
使用std::thread类来创建线程，通常需要提供一个可调用对象（如函数、函数对象或lambda表达式）作为线程的执行体。
**** 线程同步：
多个线程并发执行时可能会涉及共享资源的访问，为了避免竞态条件（Race Condition）和数据竞争（Data Race），需要使用同步机制来保护共享资源，如互斥量（std::mutex）、条件变量（std::condition_variable）等。
**** 线程池：
线程池是一种管理线程的技术，它可以重用线程以提高性能，并可以灵活地控制线程的数量。C++标准库中没有提供线程池，但可以使用第三方库（如boost::asio）或手动实现线程池。
*** 静态变量
在C++中，关键字static用于声明静态变量。静态变量具有以下特点：
**** 生命周期
静态变量的生命周期与程序的整个运行周期相同。它们在程序启动时初始化，在程序结束时销毁。因此，它们在程序的所有函数调用之间保持其值。
**** 作用域
静态变量可以具有函数作用域、文件作用域或类作用域，取决于它们的声明位置。
在函数内部声明的静态变量具有函数作用域，只能在声明它们的函数内部访问。
在文件中或类中声明的静态变量具有文件作用域或类作用域，可以在整个文件或类的范围内访问。
**** 初始化
静态变量在程序启动时进行初始化。如果没有显式初始化，静态变量将被默认初始化为0（对于基本数据类型）或nullptr（对于指针类型）。
对于函数内部的静态变量，初始化只会在第一次函数调用时进行，之后的调用不会再次初始化。
对于文件或类作用域的静态变量，初始化只会在程序启动时进行一次。
**** 存储位置
静态变量通常存储在静态存储区（静态数据区）中，这是一块特殊的内存区域，用于存储全局变量、静态变量和常量。
**** 作为类成员
在类中声明的静态成员变量属于类本身，而不是类的实例。它们只有一份副本，被所有该类的对象所共享。
*** 深浅拷贝
深拷贝（Deep Copy）和浅拷贝（Shallow Copy）是在面向对象编程中用于复制对象的两种不同方式。它们的区别在于复制对象时是否复制对象的内容。
**** 浅拷贝（Shallow Copy）：
浅拷贝是将一个对象的数据成员的值复制到另一个对象中，而不复制数据成员所指向的内容。
如果对象的数据成员是基本数据类型，浅拷贝会将其值直接复制到新对象中。
如果对象的数据成员是指针类型，则浅拷贝只会复制指针的值，而不会复制指针指向的内容。因此，新对象和原对象会共享同一块内存区域，可能会导致浅拷贝对象的析构函数重复释放同一块内存，引发内存错误。
**** 深拷贝（Deep Copy）：
深拷贝是将一个对象的数据成员的值以及数据成员所指向的内容全部复制到另一个对象中，即在新对象中重新分配内存，与原对象完全独立。
对于指针类型的数据成员，深拷贝会为新对象分配一块新的内存，将原对象所指向的内容复制到新的内存区域中。
深拷贝避免了浅拷贝可能出现的问题，每个对象都有自己独立的内存空间，不会因为一个对象的改变而影响到另一个对象。
*** const/volatile
const 和 volatile 都是C++中用于修饰变量的关键字，它们分别表示常量和易变性。它们的作用是告诉编译器如何对待被修饰的变量，以便更好地进行代码优化或确保程序的正确性。
**** const：
const用于声明常量，表示变量的值在程序执行期间不可修改。
声明为const的变量必须在声明时进行初始化，且一旦初始化后，其值不能再被修改。
声明为const的指针或引用可以指向不可变对象，但不能通过它们修改对象的值。
const还可以用于成员函数中，表示该成员函数不会修改对象的状态。
**** volatile：
volatile用于声明易变变量，表示变量的值在程序执行期间可能会被意外改变，如硬件寄存器、多线程环境中的共享变量等。
声明为volatile的变量告诉编译器不要对其进行优化，每次访问时都要从内存中读取或写入其值。
volatile变量的值可以在未经通知的情况下被外部因素改变，因此编译器不会对其进行优化。
*** RTTI (Run-Time Type Identification)
RTTI（Run-Time Type Identification）是C++语言的一项特性，用于在运行时确定对象的实际类型。它允许程序在运行时检查对象的类型信息，包括对象的类属关系、类的层次结构等。
在C++中，RTTI主要通过两种方式来实现：
**** typeid运算符：
typeid运算符用于获取对象的类型信息，返回一个std::type_info对象的引用，该对象包含有关类型的信息。
typeid运算符的语法为：typeid(expression)，其中expression可以是对象、类型或表达式。
**** dynamic_cast运算符：
dynamic_cast运算符用于在继承层次结构中进行安全的向下转型（downcasting）。
当向下转型失败时，dynamic_cast返回空指针（对于指针类型），或抛出std::bad_cast异常（对于引用类型）。

*** c++强制转换运算符
**** const_cast<type> (expr)
const_cast 运算符用于修改类型的 const / volatile 属性。除了 const 或 volatile 属性之外，目标类型必须与源类型相同。这种类型的转换主要是用来操作所传对象的 const 属性，可以加上 const 属性，也可以去掉 const 属性。
**** dynamic_cast<type> (expr)
dynamic_cast 在运行时执行转换，验证转换的有效性。如果转换未执行，则转换失败，表达式 expr 被判定为 null。dynamic_cast 执行动态转换时，type 必须是类的指针、类的引用或者 void*，如果 type 是类指针类型，那么 expr 也必须是一个指针，如果 type 是一个引用，那么 expr 也必须是一个引用。
**** reinterpret_cast<type> (expr)
reinterpret_cast 运算符把某种指针改为其他类型的指针。它可以把一个指针转换为一个整数，也可以把一个整数转换为一个指针。
**** static_cast<type> (expr)
static_cast 运算符执行非动态转换，没有运行时类检查来保证转换的安全性。例如，它可以用来把一个基类指针转换为派生类指针。
*** [[http://shaoyuan1943.github.io/2016/03/26/explain-move-forward/][std::move std::forward]]
*** c++11
*** delete[]时如何知道数组长度
[[file:assets/notes/cplusplus/1.png]]
[[file:assets/notes/cplusplus/2.png]]
*** map unordermap 区别
[[file:assets/notes/cplusplus/map.jpg]]
*** [[https://www.runoob.com/note/27755][sizeof 和 strlen区别]]
sizeof 运算符  strlen 函数
sizeof用来计算类型的大小  strlen用来计算字符串长度
*** define 和 const的区别
#define 和 const 都可以用于定义常量，但是 const 更安全、更具有类型和作用域，并且能够避免 #define 可能引发的一些问题。因此，在C++中，建议优先使用 const 来定义常量。
**** 预处理器宏 (#define)
#define 是一个预处理指令，用于创建符号常量或简单的替换文本。
#define 不会分配内存，它只是简单地将代码中的标识符替换为指定的文本。
#define 定义的常量没有类型，编译器不会对其进行类型检查，也不会进行作用域检查。
#define 适用于简单的常量定义，例如宏函数和条件编译等。
由于是简单的文本替换，#define 可能会引发一些意外的副作用，例如多次计算或重复替换。
**** 常量 (const)
const 是C++关键字，用于定义具有类型的常量。
const 定义的常量在内存中有自己的存储空间，可以被编译器优化，并具有类型安全性。
const 常量具有作用域，可以根据其定义的位置访问，也可以在不同的作用域中重新定义。
const 可以定义任何类型的常量，包括基本类型、类对象和指针等。
** TODO golang
*** [[https://zhuanlan.zhihu.com/p/323271088][gpm模型]]
*** TODO Go的GC怎么做到并发的
** 设计模式
*** 单例模式
保证一个类只有一个实例，并提供一个访问它的全局访问点。
*** 工厂模式
#+begin_src c++
#include <iostream>
#include <memory>
#include <string>

// 基类：怪物
class Monster {
public:
    virtual void attack() = 0;
};

// 具体怪物类：狼
class Wolf : public Monster {
public:
    void attack() override {
        std::cout << "Wolf attacks with claws!" << std::endl;
    }
};

// 具体怪物类：巨魔
class Troll : public Monster {
public:
    void attack() override {
        std::cout << "Troll attacks with club!" << std::endl;
    }
};

// 工厂接口：怪物工厂
class MonsterFactory {
public:
    virtual std::unique_ptr<Monster> createMonster() = 0;
};

// 具体工厂类：狼工厂
class WolfFactory : public MonsterFactory {
public:
    std::unique_ptr<Monster> createMonster() override {
        return std::make_unique<Wolf>();
    }
};

// 具体工厂类：巨魔工厂
class TrollFactory : public MonsterFactory {
public:
    std::unique_ptr<Monster> createMonster() override {
        return std::make_unique<Troll>();
    }
};

int main() {
    // 创建狼工厂
    std::unique_ptr<MonsterFactory> wolfFactory = std::make_unique<WolfFactory>();
    // 使用狼工厂创建狼怪物
    std::unique_ptr<Monster> wolf = wolfFactory->createMonster();
    // 狼怪物攻击
    wolf->attack();

    // 创建巨魔工厂
    std::unique_ptr<MonsterFactory> trollFactory = std::make_unique<TrollFactory>();
    // 使用巨魔工厂创建巨魔怪物
    std::unique_ptr<Monster> troll = trollFactory->createMonster();
    // 巨魔怪物攻击
    troll->attack();

    return 0;
}
#+end_src
*** 访问者模式
#+begin_src c++
#include <iostream>
#include <vector>

// 前向声明被访问元素类
class ElementB;

// 访问者接口
class Visitor {
public:
    virtual void visit(ElementA& element) = 0;
    virtual void visit(ElementB& element) = 0;
};

// 具体访问者类：打印访问者
class PrintVisitor : public Visitor {
public:
    void visit(ElementA& element) override {
        std::cout << "Printing ElementA" << std::endl;
    }

    void visit(ElementB& element) override {
        std::cout << "Printing ElementB" << std::endl;
    }
};

// 具体访问者类：计算访问者
class CalculationVisitor : public Visitor {
public:
    void visit(ElementA& element) override {
        std::cout << "Calculating something based on ElementA" << std::endl;
    }

    void visit(ElementB& element) override {
        std::cout << "Calculating something based on ElementB" << std::endl;
    }
};

// 被访问元素接口
class Element {
public:
    virtual void accept(Visitor& visitor) = 0;
};

// 具体被访问元素类：元素A
class ElementA : public Element {
public:
    void accept(Visitor& visitor) override {
        visitor.visit(*this);
    }
};

// 具体被访问元素类：元素B
class ElementB : public Element {
public:
    void accept(Visitor& visitor) override {
        visitor.visit(*this);
    }
};

int main() {
    std::vector<std::unique_ptr<Element>> elements;
    elements.push_back(std::make_unique<ElementA>());
    elements.push_back(std::make_unique<ElementB>());

    PrintVisitor printVisitor;
    CalculationVisitor calculationVisitor;

    for (const auto& element : elements) {
        element->accept(printVisitor);
        element->accept(calculationVisitor);
    }

    return 0;
}
#+end_src
** [[https://www.jianshu.com/p/c1015f5ffa74][进程通信]]
常用的socket方式 或者 共享内存
** TLV格式的协议
** 编译型语言和解释型语言的区别
 + 编译型语言
通过专门的编译器，将所有源代码一次性转换成特定平台（Windows、Linux 等）执行的机器码（以可执行文件的形式存在）。
编译一次后，脱离了编译器也可以运行，并且运行效率高。
可移植性差，不够灵活。
+ 解释型语言
由专门的解释器，根据需要将部分源代码临时转换成特定平台的机器码。
跨平台性好，通过不同的解释器，将相同的源代码解释成不同平台下的机器码。
一边执行一边转换，效率很低。
** C++编译器有哪些，区别在哪
历史和背景：GCC 是一个成熟的传统编译器，而 LLVM/Clang 是基于 LLVM 架构的新一代编译器。Clang 借助 LLVM 提供了更好的性能和更先进的特性。
编译速度和优化能力：Clang 倾向于提供更快的编译速度和更好的错误诊断能力，而 GCC 则提供了更丰富的代码优化能力。
错误诊断：Clang 通常提供更详细、更准确的错误信息，帮助开发者更快地定位和解决问题。
标准支持：两者都在不断更新以支持最新的 C++ 标准，但 Clang 通常更快地更新并提供更好的支持。
** [[https://www.cnblogs.com/i80386/p/4362720.html][protobuf 如何实现协议兼容]]
** TODO grpc
*** TODO grpc原理
*** TODO 如何实现rpc
** aoi
常用算法 9宫格  主城中依然消耗很大 十字链表
9宫格设计:
+ 根据地图大小初始化 aoimgr   aoimgr.instance.init(mapsize, blocksize)  块大小由视野决定
+ aoiblock 每个块内部一个map player_id player_entity 映射
+ AddToAOIMgr(player)  把玩家加入aoi管理
+ AOIUpdate 根据玩家位置 更新AOI
** HOLD [[https://halfrost.com/lru_lfu_interview/][lru缓存淘汰算法]]
用途:
如果游戏的用户很多，例如超过50万，内存就会不够，可使用LRU算法来淘汰一些数据。
流程：收到用户请求 - 在内存查找用户对象 - 如果不存在就从数据库中加载- 放入内存cache-如果cache中的用户超过20万 - 用LRU算法淘汰最古老的用户数据。
** 实现压缩算法的方法
*** 无损压缩算法：
无损压缩算法是一种可以完全还原原始数据的压缩算法，即压缩后的数据可以通过解压缩算法还原为原始数据而不损失信息。常见的无损压缩算法包括：
霍夫曼编码：根据字符出现的频率来构建不等长的编码，频率高的字符用短编码，频率低的字符用长编码，以实现数据压缩。
Lempel-Ziv 系列算法：如 LZ77、LZ78 和 LZW 等，基于字典的算法，通过查找重复出现的字符串来实现压缩。
算术编码：将整个消息编码为一个数值，根据消息的概率分布来进行编码，以实现高效的数据压缩。
*** 有损压缩算法：
有损压缩算法是一种在压缩数据时会丢失部分信息的压缩算法，压缩后的数据不能完全还原为原始数据。常见的有损压缩算法包括：
JPEG：一种用于图像压缩的有损压缩算法，主要用于压缩彩色图像。
MP3：一种用于音频压缩的有损压缩算法，主要用于压缩音乐文件。
视频编码标准：如 MPEG、H.264、H.265 等，用于视频压缩的有损压缩算法。
*** 字典压缩算法：
字典压缩算法是一种通过构建字典来实现数据压缩的算法，通常用于处理重复性较高的数据。常见的字典压缩算法包括 LZ 系列算法和 LZW 算法等。
*** 基于熵编码的压缩算法：
基于熵编码的压缩算法利用信息熵的概念来实现数据压缩，通过减少数据的冗余性来实现压缩。霍夫曼编码和算术编码都属于这类算法。
** hash
*** [[https://zhuanlan.zhihu.com/p/45430524][什么是hash表]]
*** 如何解决冲突
Hash冲突就是，不同的数据元素关键字K，计算出的哈希值相同，此时两个或多个数据，对应同一个存储地址，即产生冲突。
*** 如何优化
+ 开放定址法
    使用某种探测算法在散列表中寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到。就是即使key产生hash冲突，也不会形成链表，而是将所有元素都存入哈希表里。发生hash冲突时，就以当前地址为基准，进行再寻址的方法去寻址下一个地址，直到找到一个为空的地址为止。
    实现方式有：
    1.线性探查：发生hash冲突时，顺序查找下一个位置，直到找到一个空位置（固定步长1探测）
    2.二次探查：在发生hash冲突时，在表的左右位置进行按一定步长跳跃式探测（固定步长n探测）
    3.伪随机探测：在发生hash冲突时，根据公式生成一个随机数，作为此次探测空位置的步长（随机步长n探测）。
+ 再哈希法
    这种方式是同时构造多个哈希函数，当产生冲突时，计算另一个哈希函数的值。
    这种方法不易产生聚集，但增加了计算时间。
+ 链地址法（拉链法)
    使用链表来保存发生hash冲突的key，即不同的key有一样的hash值，将这些发生冲突的 value 组成一个单向链表
+ 建立公共溢出区
    将哈希表分为基本表和溢出表两部分，为所有发生hash冲突的关键字记录一个公共的溢出区来存放。在查找的时候，先与哈希表的相应位置比较，如果查找成功，则返回。否则去公共溢出区按顺序一一查找。在冲突数据少时性能好，冲突数据多的时候耗时
    优缺点比较：
    开放散列（open hashing）/ 拉链法（针对桶链结构）
    优点：
    在总数频繁变动的时候可以节省开销，避免了动态调整；
    记录存储在节点里，动态分布，避免了指针的开销
    删除时候比较方便
    缺点：
    因为存储是动态的，所以在查询的时候跳转需要更多的时间的开销
    在key-value可以预知，以及没有后续增改操作时候，封闭散列性能优于开放散列
    不容易序列化
    封闭散列（closed hashing）/ 开放定址法
    优点：
    容易序列化
    如果可以预知数据总数，可以创建完美哈希数列
    缺点：
    存储的记录数目不能超过桶组数，在交互时候会非常麻烦
    使用探测序列，计算时间成本过高
    删除的时候比较麻烦
*** 拉链法怎么优化
红黑树
** 网络同步
网络同步是指多个网络节点之间协调数据和状态，以确保它们在共享的环境中保持一致。在游戏开发中，常见的同步方式包括状态同步和帧同步。
*** 状态同步的实现方法
状态同步是将每个玩家的状态信息发送给所有其他玩家，以便它们在各自的客户端上进行渲染。实现方法包括：
客户端-服务器模式：所有状态更新都由服务器进行，客户端只接收服务器的状态更新。客户端通过发送用户输入（如移动、攻击）给服务器，并接收服务器返回的其他玩家的状态信息。
点对点模式：每个客户端直接发送状态信息给所有其他客户端。这种模式适用于较小规模的游戏，减少了对服务器的依赖，但需要更多的带宽和处理能力。
*** 帧同步的实现方法
帧同步是指将游戏世界的状态按照时间顺序分成一帧一帧进行同步。实现方法包括：
客户端-服务器-客户端模式：所有状态更新都由服务器进行，服务器将状态以一定的频率发送给所有客户端。客户端根据接收到的状态进行渲染，并将用户输入发送给服务器。这种方式保证了游戏的一致性，但需要额外的服务器带宽和计算资源。
去中心化帧同步：每个客户端都有自己的逻辑和状态，通过交换状态信息来保持同步。客户端之间通过对等连接进行通信，共同决定游戏状态。这种方式减轻了对服务器的依赖，但需要解决一致性和延迟等问题。
*** 两种同步方案的优缺点 各自的重连方法
**** 状态同步：
优点：
简单易实现，适用于游戏状态较为简单的情况。
降低了对带宽和服务器资源的需求。
缺点：
需要保证所有玩家收到的状态信息保持一致，容易受到延迟和丢包的影响。
客户端之间无法直接通信，需要通过服务器转发状态信息，增加了通信延迟。
重连方法：玩家重新加入游戏时，从服务器获取当前游戏状态并进行同步。
**** 帧同步：
优点：
游戏状态的同步更加精确，玩家之间的交互更加真实。
降低了对服务器的依赖，减少了通信延迟。
缺点：
对带宽和服务器资源的需求较大，特别是在大规模多人游戏中。
需要解决客户端之间的同步问题，可能会引入复杂的逻辑。
重连方法：玩家重新加入游戏时，根据当前帧状态进行同步，可能需要额外的校准机制以确保同步正确。
选择适合的同步方案需要考虑游戏的性质、规模和网络环境等因素。常见的做法是在实际开发中根据需求综合考虑各种因素,并结合状态同步和帧同步的优点来设计网络同步方案。
** [[https://lifan.tech/2020/03/08/game/game-ranking/][跳跃表排行榜]]
*** 1000人以下直接map 原理红黑树
*** 跨服排行榜 直接redis做 原理跳跃表
** TODO 应用题
*** 我有一个很大的文本，我要去除重复行(内存存的下 和 内存存不下)
*** 假设，我发一个比较大的UDP的包，一个40K的包，请问对端，收到这个40K的包，会乱序吗？
请问是什么原理？乱序的UDP，为何它的单个报文，会顺序正确？它是基于网络的哪一层，来保证报文不会乱序的？是IP层，还是哪一层？一个mpu的大小，也就1.5K吧，那底层肯定要拆包，那具体是哪一层，保证你mpu拆包完之后，再重组，还有序呢？
*** 基于刚刚的问题，请问TCP的粘包，又是怎么回事？
Nagle算法？不对不对不对。那我问你，Nagle算法去掉之后，他就不粘包了吗？Nagle算法只是一个参数，告诉Tcp的底层，尽快将业务包，往外推，而不是说，保证不粘包
*** 现memcpy拷贝函数: void memcpy(void* psrc, void* pdst, size_t length)
